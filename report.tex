\documentclass[12pt]{article}
\input{preamble}
\usepackage{url}
\usepackage{fancyhdr}
\usepackage{natbib}
\usepackage{fvextra}
\DefineVerbatimEnvironment{Code}{Verbatim}{
    fontsize=\footnotesize, % Adjust font size
    breaklines=true,        % Enable line wrapping
    breakanywhere=true      % Allow breaking anywhere
}

\title{Statistical Arbitrage and Deep Learning in the European Electricity Market \\ Deep Learning (STAT3007/7007) \\ Report - Semester 1, 2025.}

\author{\normalsize
    Filip Orestav\\ \normalsize
    49316997
    \and \normalsize
    Hans Stemshaug\\ \normalsize
    49060423
    \and \normalsize
    Nila Saravana\\ \normalsize
    48773799
    \and \normalsize
    Volter Entoma\\ \normalsize
    44782711
    \and \normalsize
    Weiming Liang\\ \normalsize
    46375489
}


\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Introduction

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

Satistical Arbitrage is a trading strategy that aims to profit from the relative price movements of two or more assets. \citep{avellaneda2010statistical} It involves identifying mispricings in the market and taking advantage of them by simultaneously buying and selling the assets. Statistical arbitrage is based on the idea that pairs or groups of historically similar stocks are expected to maintain their statistical relationship in the future, allowing traders to exploit temporary deviations from this relationship. The goal for this project is to develop a deep learning model that can apply Statistical Arbitrage to identify unfairly priced electricity prices in the European market, and to create a trading strategy to create a profitable trading strategy.

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Literature Review

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Literature Review}

\citep{guijarro2021deep}

\begin{itemize}
    \item Architecture design
    \item Main findings 
    \item (Insert a a figure of their architecture)
\end{itemize}



\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Theory

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Theory}

\subsection{Statistical Arbitrage: Cointegration}

Cointegration is a statistical property of time series variables that indicates a long-term equilibrium relationship between them, even though the individual series may be non-stationary. In statistical arbitrage, cointegration is used to identify portfolios where a linear combination of asset prices or returns results in a stationary residual, enabling mean-reverting trading strategies. 

Consider $N$ assets with log cumulative returns $R_{1,t}, R_{2,t}, \ldots, R_{N,t}$. These assets are said to be \textit{cointegrated} if there exists a vector $\boldsymbol{\beta} = (\beta_1, \beta_2, \ldots, \beta_N)$ such that the linear combination
\[
    e_t = \beta_1 R_{1,t} + \beta_2 R_{2,t} + \cdots + \beta_N R_{N,t}
\]
or, more compactly,
\begin{equation}
    e_t = \boldsymbol{\beta}^\top \mathbf{R}_t
    \label{eq:cointegration_all}
\end{equation}
where $\mathbf{R}_t = (R_{1,t}, R_{2,t}, \ldots, R_{N,t})^\top$, is a \textit{stationary process}.

The stationary residual $e_t$ oscillates around a constant mean. When $e_t$ deviates significantly from the mean, traders take positions assuming it will revert.
\begin{itemize}
  \item \textbf{Long} the undervalued assets.
  \item \textbf{Short} the overvalued assets.
\end{itemize}

For example, if $e_t > \theta$, where $\theta$ is a threshold, it indicates that the portfolio is overvalued. Traders would short the portfolio, expecting the price to revert to its mean. Conversely, if $e_t < -\theta$, it indicates that the portfolio is undervalued, and traders would go long on the portfolio.

The key assumption of cointegration is that the linear combination of asset prices or returns is stationary, even if the individual series are not. This means that the spread between the assets will revert to its mean over time, allowing traders to profit from temporary deviations from this mean.

In the context of Eurpoean electricity prices, we expect the prices in Europe to be stationary, as there are balancing effects of supply and demand. Many European countries are connected via cross-border transmission lines, allowing to equalize prices across interconnected countries. Additionally, neighbouring regions are expected to experience similar weather patterns, and seaonal demand, leading to correlated markets. Lastly, European energy policies and regulations are often harmonzied, reducing energy structural difference between countries.

\subsubsection{Log returns}

We take the log of the cumulative returns of the time series for each asset. This is done to capture any compounding differences between the assets and stabilizes large variances. Additionally, taking the cumulative returns instead of the raw prices allows us to capture the relative change in price over time, normalizing the data and making it easier to compare across different assets. Cointegration between log returns is more likely to be stationary than cointegration between raw prices.

Specifically, the log return of asset $n$ at time $t$:

\begin{equation}
    R_{i,t} = \log\left( \frac{P_{i,t}}{P_{i,0}} \right)
    \label{eq:log_cumulative_return}
\end{equation}

Where $P_{i,t}$ is the price of asset $i$ at time $t$ and $P_{i,0}$ is the price of asset $i$ at time $0$. The log return is a measure of the relative change in price over time.

\subsubsection{Cumulative residuals}
We calculate the residual of each asset by regressing the log returns of the asset on the log returns of the other assets:

\begin{equation}
    \epsilon_{n,t} = R_{n,t} - \sum_{i=1}^{N} \beta_{n,i} R_{i,t}
    \label{eq:residual}
\end{equation}

An input to the deep learning model are cumulative residuals. 
The cumulative sum mimics a \textit{price-like} behavior, which is more suitable for identifying trading signals. Raw residuals may not capture sufficient trend information, while cumulative forms highlight \textit{deviations} more clearly.

The cumulative residuals are calculated by integrating the time series of residuals over a rolling window of $L$ days.

For asset $n$, define $\epsilon^L_{n,t-1}$ as the vector of the past $L$ residuals:
\begin{equation}
    \epsilon^L_{n,t-1} = (\epsilon_{n,t-L}, \ldots, \epsilon_{n,t-1})
    \label{eq:residual_vector}
\end{equation}

The \textbf{cumulative residual vector} $x$ is then defined as:
\begin{equation}
    x := \mathrm{Int}(\epsilon^L_{n,t-1}) 
      = \left( \epsilon_{n,t-L},\ \epsilon_{n,t-L} + \epsilon_{n,t-L+1},\ \ldots,\ \sum_{l=1}^{L} \epsilon_{n,t-L-1+l} \right)
    \label{eq:cumulative_residual}
\end{equation}

Where $\mathrm{Int}$ is the integration operator. The cumulative residual vector $x$ captures the cumulative effect of the residuals over the past $L$ days, providing a measure of the overall trend in the residuals.

For the purpose of this project, we cointegrate for the length of a year. A longer length of time would allow for a more comprehesive cointegration, however, it sacrifices the ability to capture short-term trends. A shorter length of time would allow for a more responsive model, however, it sacrifices the ability to capture long-term trends. The choice of the length of the cointegration period is a trade-off between these two extremes.

Additionally, this report arbitrarily uses the cumulative residual window size of $L=30$ days. The choice of $L$ may affect the performance of the model, however, exploring different values of $L$ is out of the scope of this project.

\subsubsection{Portfolio positions}

The output for all models is a vector of $N$ values, where $N$ is the number of assets. The output is a soft normalized vector of the portfolio positions, where each value represents the weight of the corresponding asset in the portfolio. The weights are normalized such that they sum to 1, and they are constrained to be between -1 and 1. This means that the model can take long or short positions in each asset, but the total position in each asset is limited to 100\% of the portfolio value. The output takes the form of a vector $w$:

\begin{equation}
    w = (w_1, w_2, \ldots, w_N)
    \label{eq:portfolio_weights}
\end{equation}

Where $w_i$ is the weight of asset $i$ in the portfolio. The weights are normalized such that:

\begin{equation}
    \sum_{i=1}^{N} w_i = 1
    \label{eq:portfolio_weights_normalization}
\end{equation}

\subsubsection{Model performance evaluation} 

\subsubsection*{Returns}

There is a one return associated with every 30-day cumulative residual window. Each return is calculated as the matrix product of the the model outputs and the returns of the assets, one day after the end corresponding cumulative residual window. The return is calculated as:

\begin{equation}
    R_t = w^\top R_{t+1} - \sum_{i=1}^{N} w_i
    \label{eq:returns}
\end{equation}

Where $R_{t+1}$ is the vector of log returns for all assets at time $t+1$, and $w$ is the vector of portfolio weights at time $t$. 

\subsubsection*{Sharpe ratio}

The Sharpe ratio is a measure of risk-adjusted return, calculated as the ratio of the mean excess return and the standard deviation of the excess return. It is used to evaluate the performance of a trading strategy or investment portfolio. A higher Sharpe ratio indicates better risk-adjusted performance. Therefore, we use the negative of the Sharpe ratio as the loss function for our model. 

Consider the set of returns $R = (R_1, R_2, \ldots, R_T)$, where $T$ is the number of returns. The Sharpe ratio is calculated as:

\begin{equation}
    \text{Sharpe ratio} = \frac{\mathbb{E}[R]}{\text{Std}[R]}    
    \label{eq:sharpe_ratio}
\end{equation}

Where $\mathbb{E}[R]$ is the mean of the returns, and $\text{Std}[R]$ is the standard deviation of the returns. The negative of this Sharpe ratio is then used as the loss function for the model.

\clearpage



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Data

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Data}

Our dataset consists of electricity data and weather data.

\subsection{European electricity prices}

The electricity price data used in this project was taken from EMBER's \textit{European Wholesale Electricity Price Data} \citep{ember2025}.  The that was used in this report consists of daily electricity prices for 31 European countries from 2015 to 2025. The data was downloaded in CSV format and preprocessed to remove any missing values.

\subsection{European weather data}
We used the dataset \textit{ERA5 hourly time-series data on single levels from 1940 to present}. \citep{hersbach2025era5}. 

\begin{itemize}
    \item What is a available in the dataset? What and how did we extract the information we need? How did we preprocess the data?
\end{itemize}

 \clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Models

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Models}

\subsection*{Model Inputs}

We gather the log of the cumulative returns of the entire set of assets, using Equation~\ref{eq:log_cumulative_return}. We than apply cointegration for an entire year (365 days) to the log returns of the assets, to obtain the time-series residuals for each asset for the entire year, using Equation~\ref{eq:residual}. We than take the residuals of the last 30 days, starting from the first day of the cointegration period, and take cumulative sum of the residuals over a rolling window of 30 days, using Equation~\ref{eq:cumulative_residual}. This gives us a time-series of cumulative residuals for each asset, which we use as the input to the model. The input takes the form:
\begin{equation}
    x_i = \begin{pmatrix}
        \epsilon_{i,t-L} & \epsilon_{i,t-L-1} & \ldots & \epsilon_{i,t}
    \end{pmatrix}
    \label{eq:input_single_asset}
\end{equation}

where $x_i$ is the input for asset $i$, $\epsilon_{i,t-L}$ is the residual of asset $i$ at time $t-L$, $t$ is the current time within the cointegration period, and $L$ is the length of the rolling window. 
\\
The input is a concantenation of the cumulative residuals for all assets, and takes the form of a matrix $x$ of size $N \times L$, where $N$ is the number of assets and $L$ is the length of the rolling window. The input is a matrix of size $N \times L$, and takes the form:

\begin{equation}
    x = \begin{pmatrix}
        x_1 & x_2 & \ldots & x_N \\
    \end{pmatrix}
    \label{eq:input_matrix}
\end{equation}

The 30-day cumulative residuals is as a rolling window, sliding one day at a time across the the cointegration period. Therefore, the total number of inputs (data-points) for a single cointegration period is $T - L$, where $T$ is the total number of days in the cointegration period.

\vspace{20pt}

\subsection*{Model Outputs}

For every input, the model outputs a vector of portfolio weights $w$ for each asset, using Equation~\ref{eq:portfolio_weights}. The output is a soft normalized vector of the portfolio positions, where each value represents the weight of the corresponding asset in the portfolio. The weights are normalized such that they sum to 1, and they are constrained to be between -1 and 1. This means that the model can take long or short positions in each asset, but the total position in each asset is limited to 100\% of the portfolio value. 
\\

These weights are then multiplied by the price of the assets one day after the end of the associated input's cumulative residual window. This gives the model's next-day return for that input.
\\

The set of inputs creates a set of next-day returns, which are then used to calculate the Sharpe ratio of the model's performance for that cointegration period. The Sharpe ratio is calculated using Equation~\ref{eq:sharpe_ratio}, and the negative of the Sharpe ratio is used as the loss function for the model.


\subsection{CNN+FFN}
As an initial model, we implemented a simple CNN+FNN model. 

\subsection{CNN+Tranformer+FFN}

 \clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% References

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage

\bibliographystyle{apalike}
\bibliography{references.bib}


\end{document}
