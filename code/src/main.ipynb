{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8567f075",
   "metadata": {},
   "source": [
    "Import all the classes we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0766c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PriceDataLoader import PriceDataLoader\n",
    "from WeatherDataLoader import WeatherDataLoader\n",
    "from models.CNN import *\n",
    "from models.FFN import *\n",
    "import torch\n",
    "from models.CointegrationResidualGenerator import CointegrationResidualGenerator\n",
    "from PortfolioOptimizer import PortfolioOptimizer\n",
    "from Trainer import Trainer\n",
    "from PortfolioOptimizer import PortfolioOptimizer\n",
    "from DataPreparation import DataPreparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fffe12",
   "metadata": {},
   "source": [
    "Set the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1350867e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else\n",
    "                        \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5031db9c",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5c191e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from ../data/european_wholesale_electricity_price_data_daily.csv\n",
      "Weather data loaded successfully from ../data/aggregated_weather.csv\n",
      "Number of countries with complete data: 24\n",
      "Countries: ['Slovenia', 'Slovakia', 'Italy', 'Denmark', 'Latvia', 'Czechia', 'Norway', 'Romania', 'Lithuania', 'Spain', 'Sweden', 'Greece', 'Portugal', 'Hungary', 'Netherlands', 'Germany', 'Austria', 'Belgium', 'Finland', 'Poland', 'France', 'Luxembourg', 'Estonia', 'Switzerland']\n",
      "Shape of price_matrix: (3653, 24)\n",
      "Missing values in price_matrix:\n",
      "Country\n",
      "Austria        0\n",
      "Belgium        0\n",
      "Czechia        0\n",
      "Denmark        0\n",
      "Estonia        0\n",
      "Finland        0\n",
      "France         0\n",
      "Germany        0\n",
      "Greece         0\n",
      "Hungary        0\n",
      "Italy          0\n",
      "Latvia         0\n",
      "Lithuania      0\n",
      "Luxembourg     0\n",
      "Netherlands    0\n",
      "Norway         0\n",
      "Poland         0\n",
      "Portugal       0\n",
      "Romania        0\n",
      "Slovakia       0\n",
      "Slovenia       0\n",
      "Spain          0\n",
      "Sweden         0\n",
      "Switzerland    0\n",
      "dtype: int64\n",
      "Shape of returns: (3652, 24)\n",
      "Number of total features: 10\n",
      "Shape of weather_matrix: (3653, 216)\n"
     ]
    }
   ],
   "source": [
    "price_parser = PriceDataLoader(file_path=\"../data/european_wholesale_electricity_price_data_daily.csv\")\n",
    "weather_parser = WeatherDataLoader(file_path=\"../data/aggregated_weather.csv\")\n",
    "\n",
    "# Get countries with complete data (some countries do not have data for the entire time period)\n",
    "time_range = \"2015-01-01,2024-12-31\"\n",
    "countries_list = list(set(price_parser.get_countries_with_complete_data(time_range)) & \n",
    "                     set(weather_parser.get_country_list()))\n",
    "print(f\"Number of countries with complete data: {len(countries_list)}\")\n",
    "print(f\"Countries: {countries_list}\")\n",
    "\n",
    "# Generate price matrix\n",
    "price_matrix = price_parser.get_price_matrix(\n",
    "    time_range=time_range, \n",
    "    countries=countries_list, \n",
    "    fill_method=\"ffill\"\n",
    ")\n",
    "print(f\"Shape of price_matrix: {price_matrix.shape}\")\n",
    "#print(f\"Missing values in price_matrix:\\n{price_matrix.isna().sum()}\")\n",
    "\n",
    "# Compute returns\n",
    "returns = price_matrix.pct_change().dropna()\n",
    "print(f\"Shape of returns: {returns.shape}\")\n",
    "\n",
    "# Define weather features\n",
    "weather_features = [\n",
    "    'temperature_2m_mean', 'temperature_2m_min', 'temperature_2m_max',\n",
    "    'precipitation_mean', 'precipitation_min', 'precipitation_max',\n",
    "    'wind_speed_mean', 'wind_speed_min', 'wind_speed_max'\n",
    "]\n",
    "print(f\"Number of total features (price + weather): {len(weather_features) * len(countries_list) + 1}\")\n",
    "\n",
    "# Generate weather matrix\n",
    "weather_matrix = weather_parser.get_weather_matrix(\n",
    "    time_range=time_range,\n",
    "    countries=countries_list,\n",
    "    fill_method=\"ffill\",\n",
    "    features=weather_features\n",
    ")\n",
    "print(f\"Shape of weather_matrix: {weather_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cabd1a",
   "metadata": {},
   "source": [
    "Generate cointegration residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22608bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3537, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filip/stat7007/project/venv/lib/python3.12/site-packages/pandas/core/internals/blocks.py:393: RuntimeWarning: invalid value encountered in log\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "residual_generator = CointegrationResidualGenerator(price_matrix)\n",
    "residual_generator.compute_all_asset_residuals()\n",
    "asset_residuals = residual_generator.get_asset_residuals() # [num_days, num_assets (= countries)]\n",
    "print(asset_residuals.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803268cc",
   "metadata": {},
   "source": [
    "Prepare the data as input to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eb8bf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Number of returns (3507) does not match expected samples (3508)\n",
      "Train data shape: torch.Size([2455, 240, 30])\n",
      "Train returns shape: torch.Size([2455, 24])\n"
     ]
    }
   ],
   "source": [
    "data_prep = DataPreparation(\n",
    "    price_residuals=asset_residuals,\n",
    "    weather_data=weather_matrix,\n",
    "    countries=countries_list,\n",
    "    weather_features=weather_features\n",
    ")\n",
    "window_size = 30\n",
    "stride = 1\n",
    "combined_data = data_prep.prepare_rolling_windows(window_size=window_size, stride=stride)\n",
    "# [num_samples, num_features, window_size]\n",
    "\n",
    "next_day_returns = data_prep.prepare_next_day_returns(returns=returns, window_size=window_size, stride=stride)\n",
    "# [num_samples, num_countries]\n",
    "\n",
    "# Split the data in time-series\n",
    "(train_data, train_returns), (val_data, val_returns), (test_data, test_returns) = \\\n",
    "    data_prep.create_train_val_test_split(combined_data=combined_data, next_day_returns=next_day_returns)\n",
    "\n",
    "# Convert to tensors\n",
    "train_data_tensor = torch.FloatTensor(train_data).to(device)\n",
    "train_returns_tensor = torch.FloatTensor(train_returns).to(device)\n",
    "val_data_tensor = torch.FloatTensor(val_data).to(device)\n",
    "val_returns_tensor = torch.FloatTensor(val_returns).to(device)\n",
    "test_data_tensor = torch.FloatTensor(test_data).to(device)\n",
    "test_returns_tensor = torch.FloatTensor(test_returns).to(device)\n",
    "\n",
    "print(f\"Train data shape: {train_data_tensor.shape}\") # [samples, num_features, window size]\n",
    "print(f\"Train returns shape: {train_returns_tensor.shape}\") # [samples, num_countries (returns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56508e36",
   "metadata": {},
   "source": [
    "We initialize the portfolio optimizer and set up our trainer, which allows grid search for finding the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c277f20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: num_filters=8, filter_size=3, hidden_dim=64\n",
      "Testing: num_filters=8, filter_size=3, hidden_dim=128\n",
      "Testing: num_filters=8, filter_size=5, hidden_dim=64\n",
      "Testing: num_filters=8, filter_size=5, hidden_dim=128\n",
      "Testing: num_filters=8, filter_size=7, hidden_dim=64\n",
      "Testing: num_filters=8, filter_size=7, hidden_dim=128\n",
      "Testing: num_filters=16, filter_size=3, hidden_dim=64\n",
      "Testing: num_filters=16, filter_size=3, hidden_dim=128\n",
      "Testing: num_filters=16, filter_size=5, hidden_dim=64\n",
      "Testing: num_filters=16, filter_size=5, hidden_dim=128\n",
      "Testing: num_filters=16, filter_size=7, hidden_dim=64\n",
      "Testing: num_filters=16, filter_size=7, hidden_dim=128\n",
      "Testing: num_filters=32, filter_size=3, hidden_dim=64\n",
      "Testing: num_filters=32, filter_size=3, hidden_dim=128\n",
      "Testing: num_filters=32, filter_size=5, hidden_dim=64\n",
      "Testing: num_filters=32, filter_size=5, hidden_dim=128\n",
      "Testing: num_filters=32, filter_size=7, hidden_dim=64\n",
      "Testing: num_filters=32, filter_size=7, hidden_dim=128\n",
      "Best parameters: {'num_filters': 8, 'filter_size': 3, 'hidden_dim': 64} with Sharpe Ratio: 0.2293\n"
     ]
    }
   ],
   "source": [
    "portfolio_optimizer = PortfolioOptimizer(\n",
    "    window_size=window_size,\n",
    "    num_countries=len(countries_list),\n",
    "    num_weather_features=len(weather_features),\n",
    "    num_filters=8,  # Default value\n",
    "    filter_size=3,\n",
    "    hidden_dim=64,\n",
    "    num_heads=4,\n",
    "    use_transformer=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    optimizer=portfolio_optimizer,\n",
    "    train_data=train_data_tensor,\n",
    "    train_returns=train_returns_tensor,\n",
    "    val_data=val_data_tensor,\n",
    "    val_returns=val_returns_tensor,\n",
    "    lr=0.001,\n",
    "    num_epochs=100,\n",
    "    batch_size=32,\n",
    "    patience=50,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Can add more parameters to test\n",
    "param_grid = {\n",
    "    'num_filters': [8, 16, 32],\n",
    "    'filter_size': [3, 5, 7],\n",
    "    'hidden_dim': [64, 128]\n",
    "}\n",
    "best_params, best_score, best_returns = trainer.grid_search(param_grid, verbose=False)\n",
    "print(f\"Best parameters: {best_params} with Sharpe Ratio: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3330cd14",
   "metadata": {},
   "source": [
    "Reinitialize with best parameters and train on train+val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "767d2fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Validation Sharpe: 0.2172\n",
      "Epoch 10, Validation Sharpe: 0.2221\n",
      "Epoch 20, Validation Sharpe: 0.2251\n",
      "Epoch 30, Validation Sharpe: 0.2248\n",
      "Epoch 40, Validation Sharpe: 0.2253\n",
      "Epoch 50, Validation Sharpe: 0.2265\n",
      "Epoch 60, Validation Sharpe: 0.2256\n",
      "Epoch 70, Validation Sharpe: 0.2260\n",
      "Early stopping at epoch 72\n"
     ]
    }
   ],
   "source": [
    "portfolio_optimizer = PortfolioOptimizer(\n",
    "    window_size=window_size,\n",
    "    num_countries=len(countries_list),\n",
    "    num_weather_features=len(weather_features),\n",
    "    num_filters=best_params['num_filters'],\n",
    "    filter_size=best_params['filter_size'],\n",
    "    hidden_dim=best_params['hidden_dim'],\n",
    "    num_heads=4,\n",
    "    use_transformer=True,\n",
    "    device=device\n",
    ")\n",
    "trainer = Trainer(\n",
    "    optimizer=portfolio_optimizer,\n",
    "    train_data=torch.cat([train_data_tensor, val_data_tensor]),  # Combine train and val\n",
    "    train_returns=torch.cat([train_returns_tensor, val_returns_tensor]),\n",
    "    val_data=val_data_tensor,  # Still use val for early stopping\n",
    "    val_returns=val_returns_tensor,\n",
    "    lr=0.001,\n",
    "    num_epochs=100,\n",
    "    batch_size=32,\n",
    "    patience=50,\n",
    "    device=device\n",
    ")\n",
    "final_sharpe, _ = trainer.train(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491486ae",
   "metadata": {},
   "source": [
    "Evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a016eabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Sharpe Ratio on Test Set: 0.0595\n"
     ]
    }
   ],
   "source": [
    "test_sharpe, test_returns = trainer.test(test_data_tensor, test_returns_tensor)\n",
    "print(f\"Final Sharpe Ratio on Test Set: {test_sharpe:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
